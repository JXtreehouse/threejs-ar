<!DOCTYPE html>
<meta name="viewport" content="width=device-width,minimum-scale=1.0,maximum-scale=1.0,user-scalable=no"/>
<meta charset="UTF-8">

<!-- include three.js -->
<script src='../webarjs/three.js'></script>
<!-- <script src='webarjs/stats.min.js'></script>FPS的js-->

<!-- include js-aruco -->
<script src='../webarjs/svd.js'></script><!--SVD PCA的实现一般有两种，一种是用特征值分解去实现的，一种是用奇异值分解去实现-->
<script src='../webarjs/posit1-patched.js'></script><!--基于共面特征点的姿态估计-->
<script src='../webarjs/cv.js'></script><!--OPENcv -->
<script src='../webarjs/aruco.js'></script><!-- 一个微型的基于OPENCV的为了增强现实的库-->

<!-- include some extensions -->
<script src='../webarjs/threex.webcamgrabbing.js'></script>  <!--摄像头这个界面的JS-->
<script src="../js/jquery-3.1.1.min.js"></script>
<script src='../webarjs/threex.jsarucomarker.js'></script><!--跟踪识别JS-->

<script src='../vendor/three.js/examples/js/loaders/OBJLoader.js'></script>
<script src='../vendor/three.js/examples/js/loaders/MTLLoader.js'></script>
<script src='../vendor/three.js/examples/js/loaders/OBJMTLLoader.js'></script>
<script src='../webarjs/threex.universalloader.js'></script>
<style>
    #elemdiv div{
        height: 35px;width: 200px;background-color: red;color: white;text-align: center;
    }
</style>
<body style='margin: 0px; overflow: hidden;'  id="detector" class="detector">


<div><button id='picture' >PICTURE</button></div>
<canvas id="canvas" width="300" height="300" style="display:none;" ></canvas>
<div class="faces"></div>
<div id="elemdiv">


</div>



<script>




</script>
<script>
    //////////////////////////////////////////////////////////////////////////////////
    //      Test if the browser support WebGL and getUserMedia
    //////////////////////////////////////////////////////////////////////////////////
    ;(function(){
        // TODO backport those 2 in Detector.js
        var hasGetUserMedia = (navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia || navigator.msGetUserMedia) ? true : false
        var hasMediaStreamTrackSources = MediaStreamTrack.getSources ? true : false
        var hasWebGL = ( function () { try { var canvas = document.createElement( 'canvas' ); return !! ( window.WebGLRenderingContext && ( canvas.getContext( 'webgl' ) || canvas.getContext( 'experimental-webgl' ) ) ); } catch ( e ) { return false; } } )()

        if( hasWebGL === false ){
            alert('your browser doesn\'t support navigator.getUserMedia()')
        }
        if( hasMediaStreamTrackSources === false ){
            alert('your browser doesn\'t support MediaStreamTrack.getSources()')
        }
        if( hasGetUserMedia === false ){
            alert('your browser doesn\'t support navigator.getUserMedia()')
        }
    })()


    // init renderer
    var renderer    = new THREE.WebGLRenderer({
        antialias   : true,
        alpha       : true
    });
    renderer.setSize( window.innerWidth, window.innerHeight );
    document.body.appendChild( renderer.domElement );

    // array of functions for the rendering loop  渲染数组  每一次渲染时执行里面的函数
    var onRenderFcts = [];


    var scene = new THREE.Scene()
    var camera  = new THREE.PerspectiveCamera(30, window.innerWidth / window.innerHeight, 0.01, 1000);
    camera.position.z = 2;
    //  camera.position.set(4, -3, 5);

    var light = new THREE.DirectionalLight(0xffffff);
    light.position.set(4,0, 2);
    scene.add(light);



    window.addEventListener('resize', function(){
        renderer.setSize( window.innerWidth, window.innerHeight )
        camera.aspect   = window.innerWidth / window.innerHeight
        camera.updateProjectionMatrix()
    }, false)


    // render the scene
    onRenderFcts.push(function(){

        renderer.render( scene, camera );

    })




    // run the rendering loop   定时显示画面看来像动画
    var previousTime = performance.now()



    requestAnimationFrame(function animate(now){

        requestAnimationFrame( animate );



        //每次渲染执行数组里面的数
        onRenderFcts.forEach(function(onRenderFct){
            onRenderFct(now, now - previousTime)
        })

        previousTime    = now
    })


    var videoGrabbing = new THREEx.WebcamGrabbing()  //调用js里的函数


    // attach the videoGrabbing.domElement to the body
    document.body.appendChild(videoGrabbing.domElement)


</script>
<script>

    var context = canvas.getContext("2d");
    var video = document.getElementsByTagName("video")[0];
    document.getElementById("picture").addEventListener("click", function () {

        context.drawImage(video, 0, 0, 300, 300);

        var image    = canvas.toDataURL("image/png");



        var str3=image.replace(/\+/g, "-")



        $.ajax({
            url:"https://www.herozhou.com:80/recognizebody.php",
            type:"POST",
            data:'base64='+str3,
            success:function(mesg)
            {

                if(mesg!='123')
                {
                    $('#elemdiv').html('正在识别')
                    $.ajax(
                            { url: "http://www.herozhou.com:8080/ar/FaceppDelecttext=",

                                type:'GET',
                                dataType:'json',
                                success: function(data){
                                   // console.log("123123123123123");
                                        //识别出文字  跳转到店铺信息界面
                                }

                            });



                }

                else
                {
                    $('#elemdiv').html('识别失败')


                }

            }

        })
    });

</script>

<script>


</script>
<script type="text/javascript" src="http://api.map.baidu.com/api?v=2.0&ak=ipERS5S1nn9UOyrK9tNBe4WqIchFINFG"></script>
<script src="../js/jquery-3.1.1.min.js">



</script>

<script src="vendor/qtip/jquery.qtip.min.js"></script>
<script src="vendor/rainbow/rainbow.min.js"></script>

</body>

</html>